In order to represent real numbers in computer memory, a common approach is to use a floating point format. Depending on the type of encoding being used, those formats occupy different memory sizes, usually 32-bits (Single precision floating point, or binary32) or 64-bits (Double precision floating point, or binary64). \\
The value F given by the floating point format, of any kind, can be expressed as:

$$F = (-1)^{S}*M*2^{E} $$

Where 
\begin{itemize}
	\item S is the Sign (0 for positive, 1 for negative)
	\item E is the Exponent
	\item M is the Mantissa (also called Significand)
\end{itemize}

Floating-point formats and arithmetic operations are specified by the IEEE 754 standard (\url{https://standards.ieee.org/standard/754-2019.html}). \\
Under this standard (n is the number of bits reserved to the exponent):
\begin{itemize}
	\item The exponent E is unsigned, with values between 0 and ($2^{n} -1$)
	\item	The exponent E is biased, meaning that is encoded using an offset-binary representation, with the zero offset being 			$2^{n-1} – 1$
	\item	The mantissa has an hidden bit, always set to 1; therefore, the actual mantissa is 1.M
	\item	The standard also introduces some special values, for different purposes, such as Infinite (Inf) and Not-a-Number (NAN)
\end{itemize}

The single and double precision floating point representations are the two most used in modern computers and mobile phones. These devices usually aren’t particularly constrained by memory space and may actually need the accuracy offered by a 32-bit or even 64-bit representation.\\
On the other hand, many programs and situations don’t need that much accuracy in order to perform their tasks. So, we may use the half-precision floating-point format, also called binary16. For example, Embedded Systems are tipically memory and power constrained and usually don't need that much precision in order to perform their tasks. \\
The binary16 standard requires 1 bit for the sign, 5 bits for the exponent and 10 bits for the mantissa. This means that we can only represent number between $2^{-14}$ and $2^{15}$.\\
This small range of possible numbers can be a strong limitation. Therefore, another standard has been recently developed by Google, the bfloat16 (Brain Floating Point) floating-point format. This standard requires 1 bit for the sign, 8 bits for the exponent and 7 for the mantissa. \\
This format is a truncated version of the binary32 with the intent of accelerating machine learning and near-sensor computing. It preserves the approximate dynamic range of 32-bit floating-point numbers by retaining 8 exponent bits, but supports only an 8-bit precision rather than the 24-bit significand of the binary32 format. 

\begin{figure}[h]
	\centering
	\captionsetup{justification=centering}
	\includegraphics{float.png}	
	\caption{How the bits are assigned in the different standards. \\From top to bottom: binary32, binary16, bfloat16}
\end{figure}

Heap Lab has already developed an open source FPU (\url{https://gitlab.com/davide.zoni/bfloat_fpu_systemverilog}) supporting the most common operations for bfloat16 operands. \\
However, it still misses some other important operations, such as the fused Multiply-Add and the Square Root. We are requested to implement one of these operations, in particular we have chosen to develop the Square Root algorithm.\\
\\
More formally, the goals of our project are:
\begin{itemize}
	\item Add support for Square Root operation
	\item Verify the implementation correctness, comparing the results produced by our design with the ones obtained from the C function sqrt
	\item Add support for the INVSQRT operation
\end{itemize}

\clearpage
